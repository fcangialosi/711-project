\documentclass{article}

\usepackage[letterpaper, margin=1.25in]{geometry}
\setlength{\parskip}{\baselineskip}%
\setlength{\parindent}{0pt}%

\begin{document}

\title{Attestable Expiration with Trusted Platform Modules}
\author{Frank Cangialosi, Philip Kim}

\maketitle

\section{Introduction}

As data storage becomes cheaper and cheaper, the cost of archiving communication approaches zero. As a society, however, we have an interest in being able to leave the past behind. We recognize the value of the ephemeral, especially since private communications may become public through malice or legal action.

Encryption can be used to make communications private, but that only begs the question of access to the key. In recent years, there have been an increasing number of cases where courts mandated that a third party hand over its encryption keys~\cite{hushmail}, and there has been increasing pressure from law enforcement for services to incorporate a government ``back-door''~\cite{backdoor}.

What we might desire is to be able to enforce the ephemerality of some data, such that all copies of that data are not readable after a user-defined point in time. In this paper, we attempt to provide one possible realization of such a system.

The difficulty in implementing expiring information lies in the impossibility of proving a negative. Even if it were possible for the holder of sensitive data to prove that he has deleted it, he can not prove that he didn't make a copy of it beforehand. However, recent developments in computer hardware have enabled us to prove a rough equivalent, namely that data has only been accessed under certain conditions.

We leverage two areas of prior work: Trusted Platform Modules (TPMs), and Ethereum smart contracts. TPMs allow one to provably attest that a given piece of code has been executed without modification, along with its inputs and outputs, and smart contracts allow for the creation of an incentive system that encourages and rewards good behavior.

The rest of the paper is organized as follows. In Section 2, we provide necessary background information on TPMs and Ethereum, and discuss prior work on expiring information. In Section 3, we make explicit our attack model and the goals of our protocol. In Section 4, we present our protocol and in Section 5, we analyze both the security properties it achieves and the limitations in entails. We conclude in Section 6.

\section{Background and Related Work}

\subsection{Expiring Data}

One solution to the expiring message problem was the ``Vanish'' system, proposed by Geambasu et al. in 2009~\cite{vanish}. The Vanish protocol runs as follows:

\begin{itemize}
\item Alice encrypts her data using random key $K$
\item Alice divides $K$ into $N$ threshold secret shares (following Shamir 1979) and destroys the original copy
\item Alice stores all $N$ shares in a distributed hash table (DHT) at pseudo-random indices
\item Alice sends to Bob the ciphertext of the data as well as the seed used to derive the share indices
\item Bob uses the indices to retrieve $M$ shares of the key, which he uses to decrypt the ciphertext
\end{itemize}

In order to achieve the expiring property, Vanish relies on the behavior of the DHT. The prototype uses the Vuze DHT, which expunges stored data after 8 hours, and requires republishing to persist the data beyond that interval. Other DHT implementations, such as OpenDHT, allow the user to specify an expiration interval~\cite{vanish}. However, subsequent work by Wolchok et al. demonstrated that Vanish can be defeated (relatively cheaply) by crawling the Vuze DHT for all stored values~\cite{defeat-vanish}.

The fundamental assumption behind Vanish is that we can trust most nodes to behave correctly, and that securing the system is therefore a matter of raising the threshold number of nodes that must abuse that trust before the system fails. Our work differs in that we do not assume that the third-party key store behaves correctly. If the key store behaves correctly, it can provably attest to doing so. If it fails to produce this attestation, Alice can infer that the key store misbehaved.

\subsection{Trusted Platform Modules}

A Trusted Platform Module (TPM) is a dedicated, tamper-resistant hardware module that can provide a provable attestation of the current platform state to an external entity. The platform state is made up of a log of hashes of software events and a set of registers whose value is a function of the entire log of events. In response to a challenge nonce, the TPM provides (1) this untrusted log of events, and (2) a \textit{quote}, which is a digital signature covering the nonce and the current register values. An external entity can verify the log by using it to recompute the register values and confirming that they match those in the quote. Furthermore, the external entity can verify the legitamcy of the signature by validating the certificate chain of the TPM's public key and deciding whether or not to trust the issuing certificate authority~\cite{tpm-iso}.

Flicker is an infrastructure built on top of TPMs that reduces the set of code that must be trusted and verified to only Flicker (250 lines of code) and the Piece of Application Logic (PAL) itself, as opposed to the entire operating system. This provides more meaningful attestations that users can reason about and thus provides a more practical trust model for our purposes.

Flicker introduces two important features that will provide the basis of our system protocol.
First, it provides replay-resistant sealed storage. This mechanism takes as input a piece of sensitive data and a set of register values, $R$, which represents the state that must be held by the PAL in order to retreieve the values. In order to unseal the data, a PAL (either a later invocation of the original code or an entirely different PAL) must call the unseal command while executing with exactly the software state $R$. For example, if a rootkit were to be added after sealing the original data, the PAL would no longer be able to access the sealed data until the rootkit were removed because its presence would unpredictably alter the register values.

Second, Flicker introduces the notion of a TPM-based secure communication channel, which can be established as follows: (1) the PAL generates an asymmetric keypair within the protections of Flicker and puts this into sealed storage as described above, (2) the PAL transmits the public key along with an attestation to some remote party, (3) the remote party uses the attestation to verify that the PAL produced the provided public key. Once this one-way channel from the PAL to the remote party has been established, the remote party can use the PAL's public key to initiate a secure channel in the other direction~\cite{flicker}.


\subsection{Ethereum}

Ethereum is a generalized, programmable blockchain platform inspired by Bitcoin that allows anyone to easily create and run arbitrary decentralized applications. Ethereum is based upon two building blocks: ``accounts,'' which consist of a nonce, a balance, a piece of code, and storage, and ``Ether,'' which is an Ethereum-specific cryptocurrency used to pay transaction fees.

There are two types of accounts, both of which can maintain an ether balance and send  transactions: externally-controlled accounts, and contracts. Only externally-controlled accounts can initiate transactions, but contracts can fire transactons in response to others they have received. A transaction could be a simple transfer of ether, or could involve running a piece of the contract's code that updates its state.

Contracts are written in a high-level language and compiled down to an Ethereum-specific binary, which is then uploaded onto the blockchain. Once uploaded, the contract will exist and operate as long as the Ethereum network exists unless it is programmed to stop~\cite{ethereum-white}.

\section{Problem}

Suppose that Alice wishes to make a piece of sensitive data ($D$) available to Bob that expires at time $t$, without requiring that she be online after sending the data. That is, before time $t$ Bob is able to read the data whenever he pleases, but after time $t$ he is unable to read the data. %In addition, no one other than Bob (defined more precisely as any entity having access to Bob's private key) should be able to decrypt the data at \textit{any} time. We denote the receipient of sensitive data, Bob, as a single party for simplicity, but we also desire the property that Bob could be replaced with a set of users without sacrificing any of the other properties.

\subsection{Attack Model}

In this model, we make the assumption Bob is not malicious and will not attempt to store an illicit (unencrypted) copy of the message, or share his private key with other individuals. However, we wish to protect against the eventuality that Bob becomes malicious in the future (after $t$), or that Bob's system is compromised by a future adversary (Mallory), either legally or illegally. We assume in this case that at any time after $t$ Mallory can gain full access to Bob's machine, including any encryption keys stored on it.

\section{Protocol}

\subsection{Strawman}

As a strawman, Alice could send the message to Bob encrypted with key $K$, and then store $K$ on a trusted third party (Charlie). To read the data, Bob asks Charlie for $K$, and if the current time is less than $t$, Charlie returns it. Just as we assume that Bob will not make a copy of the message, we assume that he discards $K$ after each use.

The problem with this approach is that it requires extending the same trust to Charlie that we do to Bob. Charlie can retain $K$ as long as he likes and distribute it as widely as he wishes---e.g., to Mallory---and moreover he can repudiate his misbehavior without any way for Alice to prove otherwise.

\subsection{Design}

The key insight of our approach is that, through the use of a TPM, we can shift the burden of proof onto Charlie; instead of Alice proving that Charlie acted in bad faith, Charlie can prove that he acted correctly. Specifically, we mandate that Charlie is a provider of secure computing, who, in exchange for a fee, will provide attestable execution of a given program at a given time.

At the center of this approach is our custom Flicker PAL, which can be run in one of three modes:

\begin{itemize}
\item \texttt{initialize()} -- This function generates the first half of a TPM-based secure communication channel as described in Section~\ref{sec:tpm}. Namely, it generates a public/private key pair, stores the private key using the TPM's sealed storage mechanism, and outputs the public key.
\item \texttt{divulge($C$,$PK$,log)} -- The function takes as input an append-only log of every
\item \texttt{destroy(log)} --
\end{itemize}

\subsection{Protocol}

With the previous building blocks in place, we now enumerate our protocol for attestable expiration of sensitive data. For now, we make the assumption that Alice has decided on a few things out-of-band:

\begin{itemize}
\item A specific third-party, Charlie, based on her preferences for reliability vs. cost
\item The cost of storing the data, which Alice will pay to Charlie if he behaves honestly, $C_{store}$
\item The collateral that Charlie must put up in order to participate in the system, $C_{collateral}$, which makes explicit the cost of Charlie acting maliciously
\end{itemize}

We leave details of the reputation system, including the algorithm for generating these parameters based on the third-party's reputation, and the process of matching users with third-parties to future work.

\begin{enumerate}

\item Charlie creates an Ethereum smart contract, which takes as input Charlie's $C_{collateral}$ and Alice's $C_{store}$ and promises the following:
\begin{itemize}
\item If Charlie produces an attestation that proves he deleted Alice's data before $t$, the contract returns to Charlie his initial collateral and the price paid by Alice. This contract remains on the blockchain as a piece of evidence of Charlie's honesty for future parties to reference as part of the reputation system.
\item If Charlie does not produce an attestation before $t$, the contract returns $C_{store}$ to Alice and Charlie receives nothing. Consequently, this contract remains on the blockchain as a piece of evidence of Charlie's \textit{dishonesty}.
\end{itemize}

\item Alice sends the custom Flicker PAL to Charlie, and a nonce, $n$.

\item Charlie runs \texttt{PAL.initialize()}, which outputs the secure channel public key, $PK_{PAL}$, and then creates an attestation, $Attest_{initialize}$, that he ran the function correctly, based on $n$.

\item Charlie sends $PK_{PAL}$ and $Attest_{initialize}$ to Alice. After verifying the attestation, Alice knows that (a) her PAL was executed, and (b) it produced $PK_{PAL}$.

\item Alice encrypts her sensitive data $D$ using $PK_{PAL}$, to produce $C_{D,PK_{PAL}}$, which she sends to Charlie, and then goes offline.

\item In order to request $D$, Bob sends his public key, $PK_{Bob}$, to Charlie

\item Charlie runs \texttt{PAL.divulge($C_{D,PK_{PAL}}$,$PK_{Bob}$,log)}, which decrypts the original data and outputs (1) the data re-encrypted with $PK_{Bob}$,  $C_{D,PK_{Bob}}$ and a copy of the log with $PK_{Bob}$ appended, indicating that Charlie divulged $D$ to Bob.

\item Some time before $t$, Charlie runs \texttt{PAL.destroy(log)}, which deletes the encrypted data and outputs a copy of the log with ``data destroyed'' appended, and creates an attestation, $Attest_{destroy}$,

\item Charlie then submits $Attest_{desotry}$ to the Ethereum contract in order to receive his payment.

\end{enumerate}

\section{Analysis}

If Charlie produces proof that he destroyed the key, he earns his commission and Alice knows that $D$ can never be divulged again. If he does not claim his commission before time $t$, then the Ethereum contract provides proof of Charlie's misbehavior, which would utlimately reflect his reputation and thus his ability to secure future contracts.

The protocol as written does not restrict to whom Charlie divulges $D$; it simply produces a non-repudiable record of the divulgences. Suppose that Alice wishes that only Bob (or some arbitrary set of identities) is able to receive $D$. She could write the Ethereum contract in such a way that only a log that contains two entries---one corresponding to Bob and another indicating key destruction---can be used to claim the commission. If Alice wishes to make it impossible to divulge $D$ to someone other than Bob, she can embed Bob's key into the PAL. The TPM will guarantee that any modification to the PAL will produce an invalid attestation.

In addition, the protocol does not explicitly handle the case where Charlie either (1) deletes the key at some time $t_d << t$ or (2) goes offline after receiving $D$ but comes back online and successfully produces $Attest_{delete}$ before $t$. These too could be incorporated into the Ethereum contract, in which Bob could report cases of $D$ being unavailable before $t$, which would again affect Charlie's reputation.

\section{Conclusion}

In this paper, we presented a solution for attestable expiration of sensitive data based on TPMs and Ethereum smart contracts. TPMs allow a third-party to provide a cryptographic attestation of who they shared the data with and at what time they deleted the data, while smart contracts both provide incentives for good behavior and explicitly punish bad behavior in our system. Furthermore, the popularity of the Ethereum platform (and blockchain-based protocols in general) and the fact that TPMs are now shipping on almost all modern processors make this system both feasible and practical with current technologies.

\bibliographystyle{unsrt}
\bibliography{paper}

\end{document}