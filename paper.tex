\documentclass{article}

\usepackage[letterpaper, margin=1.0in]{geometry}

\begin{document}

\title{Attestable Expiration with Trusted Platform Modules}
\author{Frank Cangialosi, Philip Kim}

\maketitle

\section{Introduction}

Why it would be desirable to have information expire...

The difficult problem in implementing information that expires is the impossibility of proving a negative. Even if it were possible for the recipient to prove that he has deleted the sensitive information, he can not prove that he didn't make a copy of it beforehand.

This changes with the use of TPMs. With TPMs, it is possible to seal information such that it can only be accessed by a trusted program. Moreover, one can provably attest that the trusted program was executed with a given input and produced a given output.

Background on TPMs...

sealed storage
Secure channel
Protection against replay attacks


\section{Related Work}

One solution to the expiring message problem was proposed in 2009 by Geambasu, Kohno, Levy, and Levy as ``Vanish: Increasing Data Privacy with Self-Destructing Data''~\cite{vanish}. The Vanish protocol runs as follows:

\begin{itemize}
\item Alice encrypts her data using random key $K$
\item Alice divides $K$ into $N$ threshold secret shares (following Shamir 1979) and destroys the original copy
\item Alice stores all $N$ shares in a distributed hash table (DHT) at pseudo-random indices
\item Alice sends to Bob the ciphertext of the data as well as the seed used to derive the share indices
\item Bob uses the indices to retrieve $M$ shares of the key, which he uses to decrypt the ciphertext
\end{itemize}

In order to achieve the expiring property, Vanish relies on the behavior of the DHT. The prototype uses the Vuze DHT, which expunges stored data after 8 hours, and requires republishing to persist the data beyond that interval. Other DHT implementations like OpenDHT allow the user to specify an expiration interval.
Subsequent work by Wolchok et al. (``Defeating Vanish with Low-Cost Sybil Attacks Against Large DHTs''~\cite{defeat-vanish}) demonstrated how to defeat Vanish by crawling the Vuze DHT for all stored values. In a follow-up paper (``New Directions for Self-Destructing Data Systems"), the Vanish authors proposed methods for hardening the Vuze DHT against crawling, as well as mechanisms for splitting the key between different types of stores.
The fundamental assumption behind Vanish is that we can trust most nodes to behave correctly, and that securing the system is therefore a matter of raising the threshold number of nodes that must abuse that trust before the system fails. Our work differs in that we do not assume that the third-party key store behaves correctly. If the key store behaves correctly, it can provably attest to doing so. If it fails to produce this attestation, Alice can infer that the key store misbehaved.

Flicker~\cite{flicker,iso-tpm}\\

Ethereum~\cite{ethereum-white,ethereum-yellow}\\

\section{Design}

Suppose that Alice wishes to send a message to Bob that expires at time $t$. That is, before time $t$ Bob is able to read the message, but after time $t$ Bob is unable to read the message. In our model, Bob is not malicious and will not attempt to make an illicit copy of the message. However, we wish to protect against the eventuality that Bob becomes malicious in the future, or that Bob's system is compromised by a future adversary (Mallory). We do not wish to require that Alice be online in order for Bob to receive or read the message.

As a straw man, Alice could send the message to Bob encrypted with key $K$, and then store $K$ on a trusted third party (Charlie). To read the data, Bob asks Charlie for $K$, and if the current time is less than $t$, Charlie gives it to him. Just as we assume that Bob will not make a copy of the message, we assume that he discards $K$ after each use.

The problem with the straw man is that it requires extending the same trust to Charlie that we do to Bob. Charlie can retain $K$ as long as he likes and distribute it as widely as he wishes---e.g., to Mallory---and moreover he can repudiate his misbehavior without any way for Alice to prove otherwise.

Through use of a TPM, we can shift the burden of proof onto Charlie; instead of Alice proving that Charlie acted in bad faith, Charlie can prove that he acted correctly. Suppose, for example, that we extend the model such that Charlie is a provider of secure computing. In exchange for a fee, he will provide attestable execution of a given program at a given time.

Alice and Charlie can perform a protocol as follows:

\begin{enumerate}

\item Alice sends a Flicker PAL to Charlie. The PAL has an input parameter called `mode' which can take one of the following values: `initialize', `divulge', or `destroy'.

\item Alice asks Charlie to run the PAL with the input `mode=initialize'. When Charlie runs the PAL, the PAL establishes a secure channel. That is, it generates a public/private key pair, outputs the public key, and stores the private key in the TPM such that only this PAL is able to read it.

\item Charlie sends Alice the PAL's output as well as a Flicker attestation of the execution. After verifying the attestation, Alice knows that a) her PAL was executed, and b) it produced the attested public key.

\item Alice encrypts $K$ with the secure channel public key and sends it to Charlie. Charlie stores the ciphertext of $K$. Alice then goes offline, but not before writing an Ethereum contract, described below as step 8.

\item In order to request $K$, Bob sends his public key to Charlie. Charlie runs the PAL with three inputs: `mode=divulge', the ciphertext of $K$, and Bob's public key. The PAL decrypts $K$ using the secure channel private key, re-encrypts it using Bob's public key, and produces the re-encrypted key as output. Charlie sends the output to Bob.

\item When the PAL is run using `mode=divulge', it also produces as output an append-only log that contains one entry for every public key to whom Charlie has divulged $K$. The log is signed using the secure channel private key. This log must be included on subsequent executions that use `mode=divulge' so that the PAL can add another entry if necessary. The PAL can confirm that the required log has been provided and protect against replay attacks by using a monotonic counter, described in Flicker 4.3.2.

\item If Charlie runs the PAL with inputs comprising `mode=destroy' and the divulgence log, the PAL will append to the log the statement ``key destroyed''. It will then destroy the secure channel private key.

\item Before going offline, Alice wrote an Ethereum contract that said, ``If Charlie publishes before time $t$ a log that can be decrypted using this public key and whose last entry is ``key destroyed", I will pay him $X$ ether."

\end{enumerate}

\section{Analysis}

If Charlie produces proof that he destroyed the key, he earns his commission and Alice knows that $K$ can never be divulged again. If he does not claim his commission before time $t$, then Alice knows that something is wrong. We can tie the protocol into a reputation system by requiring as step 0 that Charlie make a public, signed commitment to fulfilling the contract.

The protocol as written does not restrict to whom Charlie divulges $K$; it simply produces a non-repudiable record of the divulgences. Suppose that Alice wishes that only Bob (or some arbitrary set of identities) is able to receive $K$. She could write the Ethereum contract in such a way that only a log that contains two entries---one corresponding to Bob and another indicating key destruction---can be used to claim the commission. If Alice wishes to make it impossible to divulge $K$ to someone other than Bob, she can embed Bob's key into the PAL. The TPM will guarantee that any modification to the PAL will produce an invalid attestation.

\bibliographystyle{unsrt}
\bibliography{paper}

\end{document}